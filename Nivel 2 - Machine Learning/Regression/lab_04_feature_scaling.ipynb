{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99239b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from lab_utils_multi import  load_house_data, run_gradient_descent \n",
    "from lab_utils_multi import  norm_plot, plt_equal_scale, plot_cost_i_w\n",
    "from lab_utils_common import dlc\n",
    "np.set_printoptions(precision=2)\n",
    "plt.style.use('./deeplearning.mplstyle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314ce544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "X_train, y_train = load_house_data()\n",
    "X_features = ['size(sqft)','bedrooms','floors','age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac044fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(1, 4, figsize=(12, 3), sharey=True)\n",
    "for i in range(len(ax)):\n",
    "    ax[i].scatter(X_train[:,i],y_train)\n",
    "    ax[i].set_xlabel(X_features[i])\n",
    "ax[0].set_ylabel(\"Price (1000's)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88017866",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set alpha to 9.9e-7\n",
    "_, _, hist = run_gradient_descent(X_train, y_train, 10, alpha = 9.9e-7)\n",
    "\n",
    "plot_cost_i_w(X_train, y_train, hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1734397f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set alpha to 9e-7\n",
    "_,_,hist = run_gradient_descent(X_train, y_train, 10, alpha = 9e-7)\n",
    "\n",
    "plot_cost_i_w(X_train, y_train, hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a161de10",
   "metadata": {},
   "outputs": [],
   "source": [
    "_,_,hist = run_gradient_descent(X_train, y_train, 10, alpha = 1e-7)\n",
    "\n",
    "plot_cost_i_w(X_train,y_train,hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a383596",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zscore_normalize_features(X):\n",
    "    \"\"\"\n",
    "    computes  X, zcore normalized by column\n",
    "    \n",
    "    Args:\n",
    "      X (ndarray (m,n))     : input data, m examples, n features\n",
    "      \n",
    "    Returns:\n",
    "      X_norm (ndarray (m,n)): input normalized by column\n",
    "      mu (ndarray (n,))     : mean of each feature\n",
    "      sigma (ndarray (n,))  : standard deviation of each feature\n",
    "    \"\"\"\n",
    "    # find the mean of each column/feature\n",
    "    mu     = np.mean(X, axis=0)                 # mu will have shape (n,)\n",
    "    # find the standard deviation of each column/feature\n",
    "    sigma  = np.std(X, axis=0)                  # sigma will have shape (n,)\n",
    "    # element-wise, subtract mu for that column from each example, divide by std for that column\n",
    "    X_norm = (X - mu) / sigma      \n",
    "\n",
    "    return (X_norm, mu, sigma)\n",
    " \n",
    "#check our work\n",
    "#from sklearn.preprocessing import scale\n",
    "#scale(X_orig, axis=0, with_mean=True, with_std=True, copy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c9e77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu     = np.mean(X_train,axis=0)   \n",
    "sigma  = np.std(X_train,axis=0) \n",
    "X_mean = (X_train - mu)\n",
    "X_norm = (X_train - mu)/sigma      \n",
    "\n",
    "fig,ax=plt.subplots(1, 3, figsize=(12, 3))\n",
    "ax[0].scatter(X_train[:,0], X_train[:,3])\n",
    "ax[0].set_xlabel(X_features[0]); ax[0].set_ylabel(X_features[3]);\n",
    "ax[0].set_title(\"unnormalized\")\n",
    "ax[0].axis('equal')\n",
    "\n",
    "ax[1].scatter(X_mean[:,0], X_mean[:,3])\n",
    "ax[1].set_xlabel(X_features[0]); ax[0].set_ylabel(X_features[3]);\n",
    "ax[1].set_title(r\"X - $\\mu$\")\n",
    "ax[1].axis('equal')\n",
    "\n",
    "ax[2].scatter(X_norm[:,0], X_norm[:,3])\n",
    "ax[2].set_xlabel(X_features[0]); ax[0].set_ylabel(X_features[3]);\n",
    "ax[2].set_title(r\"Z-score normalized\")\n",
    "ax[2].axis('equal')\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "fig.suptitle(\"distribution of features before, during, after normalization\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c300ae6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the original features\n",
    "X_norm, X_mu, X_sigma = zscore_normalize_features(X_train)\n",
    "print(f\"X_mu = {X_mu}, \\nX_sigma = {X_sigma}\")\n",
    "print(f\"Peak to Peak range by column in Raw        X:{np.ptp(X_train,axis=0)}\")   \n",
    "print(f\"Peak to Peak range by column in Normalized X:{np.ptp(X_norm,axis=0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa2a4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(1, 4, figsize=(12, 3))\n",
    "for i in range(len(ax)):\n",
    "    norm_plot(ax[i],X_train[:,i],)\n",
    "    ax[i].set_xlabel(X_features[i])\n",
    "ax[0].set_ylabel(\"count\");\n",
    "fig.suptitle(\"distribution of features before normalization\")\n",
    "plt.show()\n",
    "fig,ax=plt.subplots(1,4,figsize=(12,3))\n",
    "for i in range(len(ax)):\n",
    "    norm_plot(ax[i],X_norm[:,i],)\n",
    "    ax[i].set_xlabel(X_features[i])\n",
    "ax[0].set_ylabel(\"count\"); \n",
    "fig.suptitle(\"distribution of features after normalization\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5ecc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_norm, b_norm, hist = run_gradient_descent(X_norm, y_train, 1000, 1.0e-1, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2b9609",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict target using normalized features\n",
    "m = X_norm.shape[0]\n",
    "yp = np.zeros(m)\n",
    "for i in range(m):\n",
    "    yp[i] = np.dot(X_norm[i], w_norm) + b_norm\n",
    "\n",
    "    # plot predictions and targets versus original features    \n",
    "fig,ax=plt.subplots(1,4,figsize=(12, 3),sharey=True)\n",
    "for i in range(len(ax)):\n",
    "    ax[i].scatter(X_train[:,i],y_train, label = 'target')\n",
    "    ax[i].set_xlabel(X_features[i])\n",
    "    ax[i].scatter(X_train[:,i],yp,color=dlc[\"dlorange\"], label = 'predict')\n",
    "ax[0].set_ylabel(\"Price\"); ax[0].legend();\n",
    "fig.suptitle(\"target versus prediction using z-score normalized model\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a32da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, normalize out example.\n",
    "x_house = np.array([1200, 3, 1, 40])\n",
    "x_house_norm = (x_house - X_mu) / X_sigma\n",
    "print(x_house_norm)\n",
    "x_house_predict = np.dot(x_house_norm, w_norm) + b_norm\n",
    "print(f\" predicted price of a house with 1200 sqft, 3 bedrooms, 1 floor, 40 years old = ${x_house_predict*1000:0.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ed6d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_equal_scale(X_train, X_norm, y_train)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
